{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Browsing Agent\n",
    "This notebook will use the internet to download content like pdfs. Then an LLM will decide which files to keep. Next it will create a vector index of the files, for easy RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from open_agent import OpenAgent\n",
    "from config import Config\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import requests\n",
    "from googlesearch import search\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for PDF URLs using a query\n",
    "def search_pdf_urls(query, num_results=10):\n",
    "    pdf_urls = []\n",
    "    for url in search(query, num_results=num_results):\n",
    "        # Optionally check if the URL really ends with '.pdf'\n",
    "        if url.lower().endswith(\".pdf\"):\n",
    "            pdf_urls.append(url)\n",
    "    return pdf_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a PDF file from a given URL\n",
    "def download_pdf(url, dest_folder=\"downloads\"):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    local_filename = os.path.join(dest_folder, url.split(\"/\")[-1])\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded: {local_filename}\")\n",
    "        return local_filename\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract metadata (e.g., creation date) from the PDF\n",
    "def extract_pdf_metadata(pdf_path):\n",
    "    metadata = {}\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            metadata = reader.metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from the first few pages of the PDF\n",
    "def extract_pdf_text(pdf_path, max_pages=3):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            num_pages = len(reader.pages)\n",
    "            pages_to_read = min(num_pages, max_pages)\n",
    "            for i in range(pages_to_read):\n",
    "                page = reader.pages[i]\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for PDFs...\n",
      "Found 7 PDF URLs.\n",
      "\n",
      "Processing URL: https://www.molnlycke.com/globalassets/mepilex-border-flex-hqim005406.pdf\n",
      "Downloaded: downloads\\mepilex-border-flex-hqim005406.pdf\n",
      "Creation Date (from metadata): D:20240422151454+02'00'\n",
      "\n",
      "Processing URL: https://www.molnlycke.ca/contentassets/3a0ad2ec58d848169ae7391bb4370689/mepilexborderflex_productsheet_eng-1.pdf\n",
      "Downloaded: downloads\\mepilexborderflex_productsheet_eng-1.pdf\n",
      "Creation Date (from metadata): D:20230327105115-04'00'\n",
      "\n",
      "Processing URL: https://www.onemed.se/-/media/onemed/b2b/ligu/molnlycke/broschyr---mepilex-border-flex.pdf\n",
      "Downloaded: downloads\\broschyr---mepilex-border-flex.pdf\n",
      "Creation Date (from metadata): D:20180219131323+01'00'\n",
      "\n",
      "Processing URL: https://static.webareacontrol.com/CommonFile/mepilexborderflex-product-sheet-1647325121893.pdf\n",
      "Downloaded: downloads\\mepilexborderflex-product-sheet-1647325121893.pdf\n",
      "Creation Date (from metadata): D:20171124115227-05'00'\n",
      "\n",
      "Processing URL: https://www.molnlycke.lat/SysSiteAssets/master-and-local-markets/documents/master/wound-care-documents/ifu/pd-571466_01-ifu-mepilex-border-flex-lite.pdf\n",
      "Downloaded: downloads\\pd-571466_01-ifu-mepilex-border-flex-lite.pdf\n",
      "Creation Date (from metadata): D:20200623145657+02'00'\n",
      "\n",
      "Processing URL: https://www.molnlycke.lat/SysSiteAssets/master-and-local-markets/regulatory-requirements/mepilex-border-flex/ifu-40900-mepilex-border-flex-em_01.pdf\n",
      "Downloaded: downloads\\ifu-40900-mepilex-border-flex-em_01.pdf\n",
      "Creation Date (from metadata): D:20191018153508+02'00'\n",
      "\n",
      "Processing URL: https://www.eboshealthcare.co.nz/globalassets/ebos-nz/pdfs/moinlycke/mepilex-border-flex-family-with-mepilex-border-flex-lite_brochure.pdf\n",
      "Downloaded: downloads\\mepilex-border-flex-family-with-mepilex-border-flex-lite_brochure.pdf\n",
      "Creation Date (from metadata): D:20210531124149+10'00'\n"
     ]
    }
   ],
   "source": [
    "brand = \"m√∂lnycke mepilex border flex\"\n",
    "product_type = \"product sheet\"\n",
    "\n",
    "# Construct the search query. The filetype operator helps to target PDFs.\n",
    "query = f\"{brand} {product_type} filetype:pdf\"\n",
    "print(\"Searching for PDFs...\")\n",
    "pdf_urls = search_pdf_urls(query, num_results=10)\n",
    "print(f\"Found {len(pdf_urls)} PDF URLs.\")\n",
    "\n",
    "# Process each found PDF\n",
    "for url in pdf_urls:\n",
    "    print(f\"\\nProcessing URL: {url}\")\n",
    "    file_path = download_pdf(url)\n",
    "    if not file_path:\n",
    "        continue\n",
    "    \n",
    "    # Extract metadata such as creation date\n",
    "    metadata = extract_pdf_metadata(file_path)\n",
    "    creation_date = metadata.get(\"/CreationDate\", \"Unknown\")\n",
    "    print(f\"Creation Date (from metadata): {creation_date}\")\n",
    "    \n",
    "    # Extract text from the PDF (first few pages)\n",
    "    pdf_text = extract_pdf_text(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
